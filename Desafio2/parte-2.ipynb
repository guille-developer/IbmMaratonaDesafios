{"cells":[{"metadata":{},"cell_type":"code","source":["# MARATONA BEHIND THE CODE 2020\n","\n","## DESAFIO 2: PARTE 2"],"execution_count":62,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Introducción"]},{"metadata":{},"cell_type":"markdown","source":["En la parte 1 de este desafío, se realizó el procesamiento previo y el entrenamiento de un modelo a partir de un conjunto de datos base proporcionados. En este segundo paso, se integrará todas las transformaciones y eventos de entrenamiento creados previamente en un Pipeline completo para *deploy* en **Watson Machine Learning**."]},{"metadata":{},"cell_type":"markdown","source":["### Preparación del Notebook"]},{"metadata":{},"cell_type":"markdown","source":["Primero realizaremos la instalación do scikit-learn y la importación de las mismas bibliotecas utilizadas anteriormente"]},{"source":["!pip install scikit-learn==0.20.0 --upgrade"],"cell_type":"markdown","metadata":{}},{"source":["import json\n","import requests\n","import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import KFold, cross_validate"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["Es necesario volver a insertar el conjunto de datos base como un pandas dataframe, siguiendo las instrucciones\n","\n","![alt text](https://i.imgur.com/K1DwL9I.png \"importing-csv-as-df\")\n","\n","Después de seleccionar la opción **\"Insert to code\"**, la celda de abajo se llenará con el código necesario para importar y leer los datos en el archivo .csv como un Pandas DataFrame."]},{"metadata":{},"cell_type":"code","source":["import types\n","import pandas as pd\n","from botocore.client import Config\n","import ibm_boto3\n","\n","def __iter__(self): return 0\n","\n","# @hidden_cell\n","# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n","# You might want to remove those credentials before you share the notebook.\n","client_90a2289545db4e3eac3255f8240fbad9 = ibm_boto3.client(service_name='s3',\n","    ibm_api_key_id='RueLUmqCx740mc88R7IOOmCjjPRXIXmdSlIYLcyYQY9X',\n","    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n","    config=Config(signature_version='oauth'),\n","    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n","\n","body = client_90a2289545db4e3eac3255f8240fbad9.get_object(Bucket='desafio2ibm-donotdelete-pr-oukbdjkuqn057r',Key='dataset-tortuga-desafio-2.csv')['Body']\n","# add missing __iter__ method, so pandas accepts body as file-like object\n","if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n","\n","df_data_1 = pd.read_csv(body)\n","df_data_1.head()\n"],"execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"   Unnamed: 0               NAME   USER_ID  HOURS_DATASCIENCE  HOURS_BACKEND  \\\n0          28        Stormy Muto  58283940                7.0           39.0   \n1          81       Carlos Ferro   1357218               32.0            0.0   \n2          89  Robby Constantini  63212105               45.0            0.0   \n3         138       Paul Mckenny  23239851               36.0           19.0   \n4         143          Jean Webb  72234478               61.0           78.0   \n\n   HOURS_FRONTEND  NUM_COURSES_BEGINNER_DATASCIENCE  \\\n0            29.0                               2.0   \n1            44.0                               2.0   \n2            59.0                               0.0   \n3            28.0                               0.0   \n4            38.0                               6.0   \n\n   NUM_COURSES_BEGINNER_BACKEND  NUM_COURSES_BEGINNER_FRONTEND  \\\n0                           4.0                            0.0   \n1                           0.0                            0.0   \n2                           5.0                            4.0   \n3                           5.0                            7.0   \n4                          11.0                            0.0   \n\n   NUM_COURSES_ADVANCED_DATASCIENCE  NUM_COURSES_ADVANCED_BACKEND  \\\n0                               2.0                           5.0   \n1                               0.0                           5.0   \n2                               0.0                           4.0   \n3                               0.0                           5.0   \n4                               4.0                           3.0   \n\n   NUM_COURSES_ADVANCED_FRONTEND  AVG_SCORE_DATASCIENCE  AVG_SCORE_BACKEND  \\\n0                            0.0                   84.0               74.0   \n1                            0.0                   67.0               45.0   \n2                            1.0                    NaN               54.0   \n3                            3.0                    NaN               71.0   \n4                            0.0                   66.0               85.0   \n\n   AVG_SCORE_FRONTEND                PROFILE  \n0                 NaN     beginner_front_end  \n1                 NaN     beginner_front_end  \n2                47.0     advanced_front_end  \n3                89.0  beginner_data_science  \n4                 NaN     advanced_front_end  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>NAME</th>\n      <th>USER_ID</th>\n      <th>HOURS_DATASCIENCE</th>\n      <th>HOURS_BACKEND</th>\n      <th>HOURS_FRONTEND</th>\n      <th>NUM_COURSES_BEGINNER_DATASCIENCE</th>\n      <th>NUM_COURSES_BEGINNER_BACKEND</th>\n      <th>NUM_COURSES_BEGINNER_FRONTEND</th>\n      <th>NUM_COURSES_ADVANCED_DATASCIENCE</th>\n      <th>NUM_COURSES_ADVANCED_BACKEND</th>\n      <th>NUM_COURSES_ADVANCED_FRONTEND</th>\n      <th>AVG_SCORE_DATASCIENCE</th>\n      <th>AVG_SCORE_BACKEND</th>\n      <th>AVG_SCORE_FRONTEND</th>\n      <th>PROFILE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>28</td>\n      <td>Stormy Muto</td>\n      <td>58283940</td>\n      <td>7.0</td>\n      <td>39.0</td>\n      <td>29.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>84.0</td>\n      <td>74.0</td>\n      <td>NaN</td>\n      <td>beginner_front_end</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>81</td>\n      <td>Carlos Ferro</td>\n      <td>1357218</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>44.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>67.0</td>\n      <td>45.0</td>\n      <td>NaN</td>\n      <td>beginner_front_end</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>89</td>\n      <td>Robby Constantini</td>\n      <td>63212105</td>\n      <td>45.0</td>\n      <td>0.0</td>\n      <td>59.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>54.0</td>\n      <td>47.0</td>\n      <td>advanced_front_end</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>138</td>\n      <td>Paul Mckenny</td>\n      <td>23239851</td>\n      <td>36.0</td>\n      <td>19.0</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>71.0</td>\n      <td>89.0</td>\n      <td>beginner_data_science</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>143</td>\n      <td>Jean Webb</td>\n      <td>72234478</td>\n      <td>61.0</td>\n      <td>78.0</td>\n      <td>38.0</td>\n      <td>6.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>66.0</td>\n      <td>85.0</td>\n      <td>NaN</td>\n      <td>advanced_front_end</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":["### Construcción del Pipeline completo para el encapsulamiento en WML"]},{"metadata":{},"cell_type":"markdown","source":["#### Preparando transformaciones personalizadas para cargar en WML"]},{"metadata":{},"cell_type":"markdown","source":["En el paso anterior, se mostró cómo crear una transformación personalizada, declarando una clase Python con los métodos ``fit`` y ``transform``.\n","\n","    - Código de transformación personalizada DropColumns():\n","    \n","    from sklearn.base import BaseEstimator, TransformerMixin\n","    # All sklearn Transforms must have the `transform` and `fit` methods\n","    class DropColumns(BaseEstimator, TransformerMixin):\n","        def __init__(self, columns):\n","            self.columns = columns\n","        def fit(self, X, y=None):\n","            return self\n","        def transform(self, X):\n","            # Primero copiamos el dataframe de entrada 'X' de entrada\n","            data = X.copy()\n","            # Devolvemos un nuevo marco de datos sin las columnas no deseadas\n","            return data.drop(labels=self.columns, axis='columns')\n","\n","Para integrar estos tipos de transformaciones personalizadas con Pipelines en Watson Machine Learning, primero debe empaquetar su código personalizado como una biblioteca de Python. Esto se puede hacer fácilmente usando la herramienta *setuptools*.\n","\n","En el siguiente repositorio de git: https://github.com/vnderlev/sklearn_transforms tenemos todos los archivos necesarios para crear un paquete de Python, llamado **my_custom_sklearn_transforms**.\n","Este paquete tiene la siguiente estructura de archivos:\n","\n","    /my_custom_sklearn_transforms.egg-info\n","        dependency_links.txt\n","        not-zip-safe\n","        PKG-INFO\n","        SOURCES.txt\n","        top_level.txt\n","    /my_custom_sklearn_transforms\n","        __init__.py\n","        sklearn_transformers.py\n","    PKG-INFO\n","    README.md\n","    setup.cfg\n","    setup.py\n","    \n","El archivo principal, que contendrá el código para nuestras transformaciones personalizadas, es el archivo **/my_custom_sklearn_transforms/sklearn_transformers.py**. Si accedes a él en el repositorio, notarás que contiene exactamente el mismo código declarado en el primer paso (la clase DropColumns).\n","\n","Si has declarado sus propias transformaciones (además de la DropColumn proporcionada), debes agregar todas las clases de esas transformaciones creadas en este mismo archivo. Para hacer esto, debes hacer fork de este repositorio (esto se puede hacer en la propia interfaz web de Github, haciendo clic en el botón como se muestra en la imagen a continuación) y agregue sus clases personalizadas al archivo **sklearn_transformers.py**.\n","\n","![alt text](https://i.imgur.com/2lZ4Ty2.png \"forking-a-repo\")\n","\n","Si solo hizo uso de la transformación proporcionada (DropColumns), puede omitir este paso de fork y continuar usando el paquete base provisto. :)\n","\n","Después de preparar su paquete de Python con sus transformaciones personalizadas, reemplace el enlace del repositorio de git en la celda a continuación y ejecútelo. Si no ha preparado ninguna transformación nueva, ejecute la celda con el enlace del repositorio ya proporcionado.\n","\n","<hr>\n","    \n","**OBSERVACIÓN**\n","\n","Si la ejecución de la celda a continuación devuelve un error de que el repositorio ya existe, ejecute:\n","\n","**!rm -r -f sklearn_transforms**"]},{"metadata":{},"cell_type":"code","source":["## reemplace el enlace a continuación con el enlace de su repositorio de git (si corresponde)\n","!git clone https://github.com/guillermo-lr/sklearn_transforms.git"],"execution_count":66,"outputs":[{"output_type":"stream","text":"fatal: destination path 'sklearn_transforms' already exists and is not an empty directory.\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"code","source":["!cd sklearn_transforms\n","!ls -ltr"],"execution_count":67,"outputs":[{"output_type":"stream","text":"total 84\r\ndrwxr-x--- 5 dsxuser dsxuser  4096 Aug 16 22:11 sklearn_transforms\r\n-rw-r----- 1 dsxuser dsxuser 78558 Aug 16 22:17 sklearn_transforms.zip\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":["Para cargar el código en WML, necesitamos enviar un archivo .zip con todo el código fuente, luego comprimiremos el directorio clonado a continuación:"]},{"metadata":{"scrolled":false},"cell_type":"code","source":["!zip -r sklearn_transforms.zip sklearn_transforms"],"execution_count":68,"outputs":[{"output_type":"stream","text":"updating: sklearn_transforms/ (stored 0%)\r\nupdating: sklearn_transforms/setup.py (deflated 46%)\r\nupdating: sklearn_transforms/.git/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/tags/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/remotes/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/remotes/origin/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/remotes/origin/HEAD (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/heads/ (stored 0%)\r\nupdating: sklearn_transforms/.git/refs/heads/master (stored 0%)\r\nupdating: sklearn_transforms/.git/branches/ (stored 0%)\r\nupdating: sklearn_transforms/.git/hooks/ (stored 0%)\r\nupdating: sklearn_transforms/.git/hooks/commit-msg.sample (deflated 44%)\r\nupdating: sklearn_transforms/.git/hooks/pre-rebase.sample (deflated 59%)\r\nupdating: sklearn_transforms/.git/hooks/prepare-commit-msg.sample (deflated 46%)\r\nupdating: sklearn_transforms/.git/hooks/pre-applypatch.sample (deflated 36%)\r\nupdating: sklearn_transforms/.git/hooks/pre-push.sample (deflated 50%)\r\nupdating: sklearn_transforms/.git/hooks/applypatch-msg.sample (deflated 41%)\r\nupdating: sklearn_transforms/.git/hooks/update.sample (deflated 68%)\r\nupdating: sklearn_transforms/.git/hooks/post-update.sample (deflated 27%)\r\nupdating: sklearn_transforms/.git/hooks/pre-commit.sample (deflated 46%)\r\nupdating: sklearn_transforms/.git/HEAD (stored 0%)\r\nupdating: sklearn_transforms/.git/description (deflated 14%)\r\nupdating: sklearn_transforms/.git/config (deflated 33%)\r\nupdating: sklearn_transforms/.git/info/ (stored 0%)\r\nupdating: sklearn_transforms/.git/info/exclude (deflated 28%)\r\nupdating: sklearn_transforms/.git/packed-refs (deflated 9%)\r\nupdating: sklearn_transforms/.git/logs/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/remotes/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/remotes/origin/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/remotes/origin/HEAD (deflated 28%)\r\nupdating: sklearn_transforms/.git/logs/refs/heads/ (stored 0%)\r\nupdating: sklearn_transforms/.git/logs/refs/heads/master (deflated 28%)\r\nupdating: sklearn_transforms/.git/logs/HEAD (deflated 28%)\r\nupdating: sklearn_transforms/.git/index (deflated 53%)\r\nupdating: sklearn_transforms/.git/objects/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/45/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/45/51f3697ae7946f73c06f9f8db611c17561204a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c4/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c4/b90bb9bfb2674c96e6d8aa6cc3c8e58194f953 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/52/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/52/6fb1c4f5a0d3a2482041c7bd3f15263837acf5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cb/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cb/d827fdd178a26f42d8b01c58320b03f3eae7fa (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/25/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/25/ce21d64103b50178e1775b1850e2adbf83d1b3 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/6a/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/6a/3c980900b1ce8383ed0fd1cbcb9195d582cf4e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7b/4c55f4c0b59fa19b13cea2c228b83e3f7f004c (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7b/04014fbd820cb0146dcec7965f01f304436510 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/59/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/59/b6e39c8da7a9943135b8e6d1ed60b2bcd37ada (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1d/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1d/b2463ee70444bc63d8acc68e936daaae9165c2 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2c/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2c/de64a17098cba673b28c995910b268f5e34e7a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2c/c7a6bf2941a9d553a199a4fe658f0074a54b51 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/fd/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/fd/45fd2ece976edde5eb95b8edbe686cf109410e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/a0/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/a0/3066ce73d15efd1cc6449dea7e2b678089edd6 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d0/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d0/4d8adf3dbf886c5799f7f367168b0785f0a4f5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2f/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2f/ab3357d7d157a7a6bbda08aad6cf19970d2cc3 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/77/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/77/7798a7cedea3a2fddef8dd0b7691c9b1f9f97b (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/06/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/06/998ae152d5b5fad89c81a6853dbbc0830fd6c7 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/6e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/6e/7a361f90fff59dbacc93d91aa2c269e777b63b (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/pack/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/ffc1c2af8fa4b0ef5eef0ba4fdc441915d1a91 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/37e7cd793488c5282085286e7ecd3a9fbbb700 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/29/c65b6319ccd5b1c7da36655bb0c44e09fff991 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/04/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/04/b1ff2d79c9b11a1d494b6f6d42acb629236af4 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c0/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c0/e12da6a090fe6b2740d0cbfa7119915a00a643 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/80/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/80/b20e55b5f52a87b7769e08df221e07d9cc0f3a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/21/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/21/64a6e4b4ca3afc26c4b21982d433c8c54039a1 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1b/9e7f9e69d0cac5283f551433cdaf8e65199698 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/61/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/61/e62b4f1623878ae0d92ffa812570be417feb82 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c3/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c3/9f70251de841c8e55e9c58d2fa7dbbe2d2fb0f (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/58/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/58/25ba31fa0c00d63a9dc9865e0c848442a6fbcd (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ee/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ee/96aaec3459bae7b27b49e17f867db49c3257a8 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f9/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f9/842759dbd395649399f47479175e044b6b40ae (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/0e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/0e/cc61a0a4baff0885426f45a8fcb9fbb78f8009 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/22/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/22/2e658014f5f2a43e16ce3c5e896e00fef1f3d5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cc/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cc/fdab500390127d0490aaf9ee369565b05c41b4 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/60/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/60/98bca26366cc6579ba18967afeb36a29033e88 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8b/137891791fe96927ad78e64b0aad7bded08bdc (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1e/1e45038dfc30ed50e6d081ec85e8a3fdfb8913 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/5a/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/5a/b47e5cada9bcefbd66782d50edf2a86005dcb5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/39/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/39/d4d3fd1cc23783dbadb2d673f3758863106854 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/39/ccfbaf81e116c9eb9781c7cd0b7acdd5ad10aa (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f2/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/f2/598626ccd27c586d5b759e5186abc64c058912 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/b9/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/b9/77ebbdff503982537b517a005cddca9680020b (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/af/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/af/1140cfcb4e33bc03d9b067c1f7d70147d043d7 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/4b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/4b/590440a5e39f3e1b29717da0528be152efd895 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/9b/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/9b/9fe6ce4d68c31dfc1eb7e923e5c90b0595b24d (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8c/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8c/d09104c54f140d61a6e9fa6c2142d4565ee302 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/8c/46dcca21d6dd2c23afb4a858d2b77d56bbf050 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/46/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/46/862abd9b50e51c99a1f65be820af360594f8c2 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/82/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/82/e0b0b52c39cd1840e7853e6d00986fae5683f4 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/99/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/99/bde3a281e0a208866b47dcde00a4e4cd8afca0 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cf/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/cf/351992ffc1752760f41befc530010b8b5c5915 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/2e/2e5168d3c37ccbaeb3b899da3f30fb6bc70031 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ab/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/ab/c06aec7285663125169e574aae624d1acc6441 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/97/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/97/613a414f5c89bf36e8ceccaa39301346451d5e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/info/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1c/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/1c/49d4656922fe1182c905339ec7a468e6881d99 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d7/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d7/cfed1a9cf21930beb933ecafb2e3d4d3a77874 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/da/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/da/64b79708ea475e8c6b484d837676ce91d9801e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/81/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/81/08ed3c16f2603b34128eb2248d31bd01711cd7 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/26/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/26/3abe321ee224139817e2325d5c91ac8f0eed50 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e8/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e8/8e9a7c9bc5a570d097ba4001ea0c327cba6f0a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/bc/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/bc/bd8f17177cd1afe8396315d2039283fa993390 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/bc/a817006f92d9e390374c1ed6467fad5ff7bab0 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/54/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/54/a860e717a464beb16bcb21419ab86f8351fbf0 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/54/5d0fb908f733cd9eed69b0004a2dfeb33b5c48 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7e/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7e/ae3d08dc940e367e3c1e2ac7a35a8b00df2e12 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/34/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/34/5dcb41e981077e03d8d70fa779357a3ae6a2d9 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d3/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/d3/697484c118054fc68a13eaac93c2f93536b77e (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/b6/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/b6/979f3149443c66198e505c1e761f2766b4ea35 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7d/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/7d/8a30ead8f79422b8cf6bc9af42974eba67c5d5 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c6/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/c6/4e501fc43c00861aa7ccae744058ba87c304fd (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/5f/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/5f/8651fdee582fb466191c1eec954122f729f515 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/67/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/67/4f0053f6ba965a37dba33c6e1e492e344c6957 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/24/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/24/7b371c9092731e07412dc5286126ed3a18756a (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/aa/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/aa/1db9544c86800c5018cb8f28d1e74fbd192991 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/05/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/05/6cab60f81eb62f20ffd3cab59b6d232f0188e9 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e6/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e6/38bef8762e368b7610f211f0cb7a8694ce4824 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391 (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/85/ (stored 0%)\r\nupdating: sklearn_transforms/.git/objects/85/bd34a4ae5f5c965a082a26b38a3268a662ae2b (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms/ (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms/sklearn_transformers.py (deflated 74%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms/__init__.py (stored 0%)\r\nupdating: sklearn_transforms/README.md (deflated 15%)\r\nupdating: sklearn_transforms/setup.cfg (deflated 16%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/ (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/dependency_links.txt (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/top_level.txt (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/SOURCES.txt (deflated 48%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/not-zip-safe (stored 0%)\r\nupdating: sklearn_transforms/my_custom_sklearn_transforms.egg-info/PKG-INFO (deflated 33%)\r\nupdating: sklearn_transforms/PKG-INFO (deflated 31%)\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":["Con el archivo zip de nuestro paquete cargado en el Kernel de este notebook, podemos usar la herramienta pip para instalarlo, de acuerdo con la celda a continuación:"]},{"metadata":{},"cell_type":"code","source":["!pip install sklearn_transforms.zip"],"execution_count":69,"outputs":[{"output_type":"stream","text":"Processing ./sklearn_transforms.zip\nBuilding wheels for collected packages: my-custom-sklearn-transforms\n  Building wheel for my-custom-sklearn-transforms (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.tmp/pip-ephem-wheel-cache-lppnk4gb/wheels/8f/88/32/f886e7510a37b111e2a1b7e689e04450acda46732970a7ed78\nSuccessfully built my-custom-sklearn-transforms\nInstalling collected packages: my-custom-sklearn-transforms\n  Found existing installation: my-custom-sklearn-transforms 1.0\n    Uninstalling my-custom-sklearn-transforms-1.0:\n      Successfully uninstalled my-custom-sklearn-transforms-1.0\nSuccessfully installed my-custom-sklearn-transforms-1.0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":["¡Ahora podemos importar nuestro paquete personalizado a nuestro notebook!\n","\n","Importaremos la transformación DropColumns. Si tienes otras transformaciones personalizadas, ¡no olvides importarlas!"]},{"metadata":{},"cell_type":"code","source":["from my_custom_sklearn_transforms.sklearn_transformers import DropColumns, Scalador\n"],"execution_count":70,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### Declarando un Pipeline\n","\n","Después de importar transformaciones personalizadas como un paquete de Python, podemos proceder a la declaración de nuestro Pipeline.\n","\n","El proceso es muy similar al realizado en la primera etapa, pero con algunas diferencias importantes, ¡así que presta mucha atención!\n","\n","El Pipeline de ejemplo tiene tres etapas: \n","\n","    - Remover las colunas \"NAME\" e \"Unnamed: 0\"\n","    - Asignar \"ceros\" a todos los valores faltantes\n","    - insertar datos preprocesados como entrada en un modelo entrenado\n","    \n","Recordando, la entrada de este Pipeline será el conjunto de datos brutos proporcionados, excepto la columna \"PROFILE\" (variable de objetivo que será determinada por el modelo).\n","\n","Entonces tendremos 16 valores de entrada en el **PIPELINE** (en el modelo habrá 14 entradas, ya que las columnas \"NAME\" y \"Unnamed: 0\" se eliminarán en la primera etapa después de la transformación DropColumns).\n","\n","\n","    Unnamed: 0                          - Esta columna no tiene nombre y debe ser eliminada del dataset\n","    NAME                                - Nombre del estudiante\n","    USER_ID                             - Número de identificación del estudiante\n","    HOURS_DATASCIENCE                   - Número de horas de estudio en Data Science\n","    HOURS_BACKEND                       - Número de horas de estudio en Web (Back-End)\n","    HOURS_FRONTEND                      - Número de horas de estudio en Web (Front-End)\n","    NUM_COURSES_BEGINNER_DATASCIENCE    - Número de cursos de nivel principiante en Data Science completados por el estudiante\n","    NUM_COURSES_BEGINNER_BACKEND        - Número de cursos de nivel principiante en Web (Back-End) completados por el estudiante\n","    NUM_COURSES_BEGINNER_FRONTEND       - Número de cursos de nivel principiante en Web (Front-End) completados por el estudiante\n","    NUM_COURSES_ADVANCED_DATASCIENCE    - Número de cursos de nivel avanzado en Data Science completados por el estudiante\n","    NUM_COURSES_ADVANCED_BACKEND        - Número de cursos de nivel avanzado en Web (Back-End) completados por el estudiante\n","    NUM_COURSES_ADVANCED_FRONTEND       - Número de cursos de nivel avanzado en Web (Front-End) completados por el estudiante\n","    AVG_SCORE_DATASCIENCE               - Promedio acumulado en cursos de Data Science completados por el estudiante\n","    AVG_SCORE_BACKEND                   - Promedio acumulado en cursos de Web (Back-End) completados por el estudiante\n","    AVG_SCORE_FRONTEND                  - Promedio acumulado en cursos de Web (Front-End) completados por el estudiante\n","\n","La salida del Pipeline será un valor estimado para la columna \"PROFILE\"."]},{"metadata":{},"cell_type":"code","source":["# Crear una transformación personalizada ``DropColumns``\n","\n","rm_columns = DropColumns(\n","    columns=[\"NAME\", \"Unnamed: 0\"]\n",")"],"execution_count":71,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Crear un objeto ``SimpleImputer``\n","\n","si = SimpleImputer(\n","    missing_values=np.nan,  # los valores que faltan son del tipo ``np.nan`` (Pandas estándar)\n","    strategy='constant',  # la estrategia elegida es cambiar el valor faltante por una constante\n","    fill_value=0,  # la constante que se usará para completar los valores faltantes es un int64 = 0\n","    verbose=0,\n","    copy=True\n",")"],"execution_count":72,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# si.fit(df_data_1)\n","# df_data_1 = si.transform(df_data_1)"],"execution_count":73,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["sc = Scalador()\n"],"execution_count":74,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["# Definicion de columnas que seran features\n","features = [\n","    \"Unnamed: 0\", \"NAME\", \"USER_ID\", \"HOURS_DATASCIENCE\", \"HOURS_BACKEND\", \"HOURS_FRONTEND\",\n","    \"NUM_COURSES_BEGINNER_DATASCIENCE\", \"NUM_COURSES_BEGINNER_BACKEND\", \"NUM_COURSES_BEGINNER_FRONTEND\",\n","    \"NUM_COURSES_ADVANCED_DATASCIENCE\", \"NUM_COURSES_ADVANCED_BACKEND\", \"NUM_COURSES_ADVANCED_FRONTEND\",\n","    \"AVG_SCORE_DATASCIENCE\", \"AVG_SCORE_BACKEND\", \"AVG_SCORE_FRONTEND\"\n","]\n","\n","# Definición de variable objetico\n","target = [\"PROFILE\"]\n","\n","# Preparación de argumentos para los métodos de la biblioteca ``scikit-learn``\n","X = df_data_1[features]\n","y = df_data_1[target]"],"execution_count":75,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**¡¡ATENCIÓN!!**\n","\n","La celda de arriba, aunque muy similar a la definición de características en la primera etapa de este desafío, ¡tiene una gran diferencia!\n","\n","Contiene las columnas \"NAME\" y \"Unnamed: 0\" como features. Esto se debe a que en este caso estas son las entradas *PIPELINE*, no el modelo."]},{"metadata":{},"cell_type":"code","source":["# Separación de datos en un conjunto de entrenamiento y un conjunto de prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"],"execution_count":76,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["En la celda a continuación, se declara un objeto scikit-learn **Pipeline**, donde se declara el parámetro *steps*, que no es más que una lista de los pasos en nuestro pipeline:\n","\n","    'remove_cols'     - transformación personalizada DropColumns\n","    'imputer'         - transformación scikit-learn incorporada para asignar valores faltantes\n","    'dtc'             - un clasificador a través del árbol de decisión\n","\n","Tenga en cuenta que pasamos como transformaciones instanciadas anteriormente, bajo el nombre `rm_columns` y` si`."]},{"metadata":{},"cell_type":"code","source":["# Creación de nuestro pipeline para almacenamiento en Watson Machine Learning:\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","\n","\n","\n","my_pipeline = Pipeline(\n","    steps=[\n","        ('remove_cols', rm_columns),\n","        ('scalae', sc),\n","        ('imputer', si),\n","        ('dtc', QuadraticDiscriminantAnalysis()),\n","    ]\n",")"],"execution_count":77,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Luego, ejecutaremos el método `fit ()` de Pipeline, realizando el preprocesamiento y entrenamiento del modelo a la vez."]},{"source":["# Inicialización de Pipeline (preprocesamiento y formación de modelos)\n","my_pipeline.fit(X_train, y_train)"],"cell_type":"markdown","metadata":{}},{"source":[],"cell_type":"markdown","metadata":{}},{"source":[],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["Ahora que tenemos un pipeline completo, con los pasos de preprocesamiento configurados y también un modelo por árbol de decisiones ya entrenado, ¡podemos integrarnos con Watson Machine Learning!"]},{"metadata":{},"cell_type":"markdown","source":["### Encapsulación de un Pipeline personalizado en Watson Machine Learning "]},{"metadata":{},"cell_type":"markdown","source":["#### Establecer una conexión entre el cliente WML Python y su instancia de servicio en la nube"]},{"source":["# Biblioteca de Python con implementación de un cliente HTTP para la API de WML\n","from watson_machine_learning_client import WatsonMachineLearningAPIClient"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["Las siguientes celdas desplegarán el pipeline declarado en este notebook en WML. Continúe solo si ya está satisfecho con su modelo y cree que es hora de implementar su solución.\n","\n","Pegue las credenciales de su instancia de Watson Machine Learning en la variable de la celda siguiente.\n","\n","Es importante que la variable que contiene los valores tenga el nombre de `` wml_credentials`` para que las siguientes celdas de este notebook se ejecuten correctamente."]},{"source":["wml_credentials = {\n","  \"apikey\": \"key\",\n","  \"iam_apikey_description\": \"Auto-generated for key key\",\n","  \"iam_apikey_name\": \"Credenciales de servicio-1\",\n","  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n","  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/key\",\n","  \"instance_id\": \"key\",\n","  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n","}"],"cell_type":"markdown","metadata":{}},{"source":["# Creación de un objeto cliente de Watson Machine Learning a partir de las credenciales proporcionadas\n","\n","clientWML = WatsonMachineLearningAPIClient(wml_credentials)"],"cell_type":"markdown","metadata":{}},{"source":["# Extracción de detalles de su instancia de Watson Machine Learning\n","\n","instance_details = clientWML.service_instance.get_details()\n","print(json.dumps(instance_details, indent=4))"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["**¡¡ATENCIÓN!!**\n","\n","¡Preste atención a los límites de consumo de su instancia de Watson Machine Learning!\n","\n","Si expira la capa libre, no podrá evaluar su modelo (¡ya que es necesario realizar algunas llamadas a API que consumen predicciones!)"]},{"metadata":{},"cell_type":"markdown","source":["#### Listado de todos los artefactos almacenados en su WML"]},{"metadata":{},"cell_type":"markdown","source":["Para listar todos los artefactos almacenados en Watson Machine Learning, puede utilizar la siguiente función:\n","\n","    clientWML.repository.list()"]},{"metadata":{},"cell_type":"code","source":["# Listado de todos los artefactos almacenados en su WML\n","\n","clientWML.repository.list()"],"execution_count":83,"outputs":[{"output_type":"stream","text":"------------------------------------  ----------------------------------------------------  ------------------------  -----------------  -----------------\nGUID                                  NAME                                                  CREATED                   FRAMEWORK          TYPE\n62f9461b-d9bb-4a4c-8fd7-5e544460f2f8  desafio-2-mbtc2020-pipeline-es-2                      2020-08-16T22:13:37.581Z  scikit-learn-0.20  model\nc59047f4-3714-4ec0-8fb2-efb5366a7b6a  desafio-2-mbtc2020-pipeline-es-2                      2020-08-16T16:55:48.852Z  scikit-learn-0.20  model\n71eb9f8f-4ca4-4642-9d3c-c1bc9b747e99  desafio-2-mbtc2020-deployment-es-2                    2020-08-16T22:13:41.219Z  scikit-learn-0.20  online deployment\n530768c7-4df5-4bba-ab47-137d6226dbfb  desafio-2-mbtc2020-deployment-es-2                    2020-08-16T16:57:54.119Z  scikit-learn-0.20  online deployment\nbe01f033-fde3-4455-b945-fd4353512571  my_custom_sklearn_transform_es_2_guillermo_rodriguez  2020-08-16T22:13:33.588Z  -                  python library\n42989bdc-8881-4ed5-9b15-b2eb22248e88  my_custom_sklearn_transform_es_2                      2020-08-16T16:28:34.776Z  -                  python library\n60dc1e15-760c-421d-b40b-ee98c0fb9da5  my_custom_wml_runtime_es_2                            2020-08-16T22:13:36.122Z  -                  python runtime\n27dde2a2-f25b-43cc-8f1b-c722ee7fcaa6  my_custom_wml_runtime_es_2                            2020-08-16T16:29:45.181Z  -                  python runtime\n------------------------------------  ----------------------------------------------------  ------------------------  -----------------  -----------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":["En el plan LITE de Watson Machine Learning, solo se puede implementar un modelo a la vez. Si ya tiene un modelo en línea en su instancia, puede eliminarlo usando el método clientWML.repository.delete ():\n","\n","    artifact_guid = \"359c8951-d2fe-4063-8706-cc06b32d5e0d\"\n","    clientWML.repository.delete(artifact_guid)"]},{"metadata":{},"cell_type":"markdown","source":["#### Crear una nueva definición de paquete Python personalizada en WML"]},{"metadata":{},"cell_type":"markdown","source":["El primer paso para realizar su implementación es almacenar el código de las transformaciones personalizadas creadas.\n","\n","Para este paso solo necesitamos el archivo .zip del paquete creado (¡que ya hemos cargado en el Kernel!)"]},{"source":["# Definición de metadatos de nuestro paquete con transformaciones personalizadas \n","pkg_meta = {\n","    clientWML.runtimes.LibraryMetaNames.NAME: \"my_custom_sklearn_transform_es_2_guillermo_rodriguez_code\",\n","    clientWML.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom sklearn transform\",\n","    clientWML.runtimes.LibraryMetaNames.FILEPATH: \"sklearn_transforms.zip\",  # Note que estamos utilizando o .zip creado anteriormente!\n","    clientWML.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n","    clientWML.runtimes.LibraryMetaNames.PLATFORM: { \"name\": \"python\", \"versions\": [\"3.6\"] }\n","}\n","custom_package_details = clientWML.runtimes.store_library( pkg_meta )\n","custom_package_uid = clientWML.runtimes.get_library_uid( custom_package_details )\n","\n","print(\"\\n Lista de artefactos en tiempo de ejecución almacenados en WML:\")\n","clientWML.repository.list()"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["#### Creación de una nueva definición personalizada de runtime Python en WML\n","\n","El segundo paso es almacenar una definición de runtime Python para usar nuestra biblioteca personalizada.\n","\n","Esto puede hacerse de la siguiente manera:"]},{"source":["runtime_meta = {\n","    clientWML.runtimes.ConfigurationMetaNames.NAME: \"my_custom_wml_runtime_es_2\",\n","    clientWML.runtimes.ConfigurationMetaNames.DESCRIPTION: \"A Python runtime with custom sklearn Transforms\",\n","    clientWML.runtimes.ConfigurationMetaNames.PLATFORM: {\n","        \"name\": \"python\",\n","        \"version\": \"3.6\"\n","    },\n","    clientWML.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [ custom_package_uid ]\n","}\n","runtime_details = clientWML.runtimes.store( runtime_meta )\n","custom_runtime_uid = clientWML.runtimes.get_uid( runtime_details )\n","\n","print(\"\\n Detalles de runtime almacenados:\")\n","print(json.dumps(runtime_details, indent=4))"],"cell_type":"markdown","metadata":{}},{"source":["# Listando todos runtimes armazenados no seu WML:\n","clientWML.runtimes.list()"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["#### Crear una nueva definición de Pipeline personalizado en WML\n","\n","Finalmente crearemos una definición (metadatos) para que nuestro Pipeline se aloje en WML.\n","\n","Definimos como parámetros un nombre para el artefacto y el ID de runtime creado anteriormente."]},{"source":["model_meta = {\n","    clientWML.repository.ModelMetaNames.NAME: 'desafio-2-mbtc2020-pipeline-es-2',\n","    clientWML.repository.ModelMetaNames.DESCRIPTION: \"my pipeline for submission\",\n","    clientWML.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid\n","}"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["Luego llamamos al método para almacenar la nueva definición:"]},{"source":["# Función para almacenar una definición de Pipeline en WML \n","stored_model_details = clientWML.repository.store_model(\n","    model=my_pipeline,  # `my_pipeline` es la variable creada previamente y contiene nuestro Pipeline ya entrenado :)\n","    meta_props=model_meta,  # Metadatos definidos en la celda anterior\n","    training_data=None  # No cambie este parámetro\n",")\n","\n","print(\"\\n Lista de artefactos almacenados en WML:\")\n","clientWML.repository.list()\n","\n","# Detalles del modelo alojado en Watson Machine Learning\n","print(\"\\n Metadatos almacenados del modelo:\")\n","print(json.dumps(stored_model_details, indent=4))"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["#### Despliegue de su modelo para consumo inmediato por otras aplicaciones"]},{"source":["# El modelo finalmente se implementa usando el método `` deployments.create () ``\n","\n","model_deployment_details = clientWML.deployments.create(\n","    artifact_uid=stored_model_details[\"metadata\"][\"guid\"],  # No cambie este parámetro\n","    name=\"desafio-2-mbtc2020-deployment-es-2\",\n","    description=\"Solução do desafio 2 - MBTC\",\n","    asynchronous=False,  # No cambie este parámetro\n","    deployment_type='online',  # No cambie este parámetro\n","    deployment_format='Core ML',  # No cambie este parámetro\n","    meta_props=model_meta  # No cambie este parámetro\n",")"],"cell_type":"markdown","metadata":{}},{"metadata":{},"cell_type":"markdown","source":["#### Prueba de un modelo alojado en Watson Machine Learning"]},{"source":["# Recuperando a URL endpoint do modelo hospedado na célula anterior\n","\n","model_endpoint_url = clientWML.deployments.get_scoring_url(model_deployment_details)\n","print(\"Su URL de llamada a la API es: {}\".format(model_endpoint_url))"],"cell_type":"markdown","metadata":{}},{"source":["# Detalles del despliegue realizado\n","\n","deployment_details = clientWML.deployments.get_details(\n","    deployment_uid=model_deployment_details[\"metadata\"][\"guid\"]  # este es su ID de implementación!\n",")\n","\n","print(\"Metadatos de despliegue realizado: \\n\")\n","print(json.dumps(deployment_details, indent=4))"],"cell_type":"markdown","metadata":{}},{"source":["scoring_payload = {\n","    'fields': [\n","        \"Unnamed: 0\", \"NAME\", \"USER_ID\", \"HOURS_DATASCIENCE\", \"HOURS_BACKEND\", \"HOURS_FRONTEND\",\n","        \"NUM_COURSES_BEGINNER_DATASCIENCE\", \"NUM_COURSES_BEGINNER_BACKEND\", \"NUM_COURSES_BEGINNER_FRONTEND\",\n","        \"NUM_COURSES_ADVANCED_DATASCIENCE\", \"NUM_COURSES_ADVANCED_BACKEND\", \"NUM_COURSES_ADVANCED_FRONTEND\",\n","        \"AVG_SCORE_DATASCIENCE\", \"AVG_SCORE_BACKEND\", \"AVG_SCORE_FRONTEND\"\n","    ],\n","    'values': [\n","        [\n","            0,\"Paula Waters\",85123728,0.0,0.0,86.0,72.0,42.0,0.0,0.0,26.0,184.0,37.0,63.0,38.0,\n","        ]\n","    ]\n","}\n","\n","# Definición de la variable objetivo\n","target = [\"PROFILE\"]\n","\n","print(\"\\n Payload de datos para clasificar:\")\n","print(json.dumps(scoring_payload, indent=4))"],"cell_type":"markdown","metadata":{"scrolled":false}},{"metadata":{},"cell_type":"code","source":["result = clientWML.deployments.score(\n","    model_endpoint_url,\n","    scoring_payload\n",")\n","\n","print(\"\\n Resultados:\")\n","print(json.dumps(result, indent=4))"],"execution_count":93,"outputs":[{"output_type":"stream","text":"\n Resultados:\n{\n    \"fields\": [\n        \"prediction\",\n        \"probability\"\n    ],\n    \"values\": [\n        [\n            \"beginner_backend\",\n            [\n                0.0012497779202254242,\n                0.03809139531242915,\n                0.1944838194079779,\n                0.5904812452043887,\n                0.17475907371419067,\n                0.0009346884407881788\n            ]\n        ]\n    ]\n}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":["<hr>\n","\n","## ¡Felicidades! \n","\n","Si todo salió bien, ¡ya tiene un clasificador basado en aprendizaje automático encapsulado como una API REST!\n","\n","Para probar tu solución integrada con un asistente virtual y realizar el envío, visita la página:\n","\n","https://tortuga.maratona.dev\n","\n","Necesitarás la URL del endpoint de tu modelo y las credenciales WML :)"]},{"source":[],"cell_type":"markdown","metadata":{}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.6","language":"python"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}